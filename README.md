# ğŸš’ San Francisco Fire Calls Analysis with PySpark

This project uses **PySpark** to analyze San Francisco fire calls data. The analysis demonstrates a full, end-to-end data processing workflow using Spark DataFrames, addressing key questions related to call types, seasonal trends, neighborhood response times, and other statistical insights.

## ğŸ“„ Overview
This project aims to explore various statistical questions using a PySpark application based on the **sf-fire-calls.csv** dataset. Each question is addressed with Spark DataFrame operations, showing the power of PySpark for large-scale data analysis.

## ğŸ’» Running the Project
Make sure the `sf-fire-calls.csv` file is in the same directory as the code file. You can download the dataset from the following link:

[Download the sf-fire-calls.csv dataset](https://github.com/databricks/LearningSparkV2/tree/master/databricks-datasets/learning-spark-v2/sf-fire)

## ğŸ” Summary
This project showcases how to leverage PySpark for analyzing a large dataset on fire calls, extracting valuable insights regarding call types, timing, response delays, and neighborhood-specific statistics.

## ğŸ“ Notes
- This project was executed on a DataBriks Spark cluster.
